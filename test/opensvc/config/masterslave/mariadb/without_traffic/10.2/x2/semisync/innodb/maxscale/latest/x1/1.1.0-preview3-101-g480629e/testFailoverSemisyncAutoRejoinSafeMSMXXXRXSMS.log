2017/08/06 12:03:04 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71 [192.168.100.70 192.168.100.71]
2017/08/06 12:03:04 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/06 12:03:04 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/06 12:03:04 [ux_dck_zpool_loop] INFO  - Failover in automatic mode
2017/08/06 12:03:04 [ux_dck_zpool_loop] ERROR - File error: open /var/lib/replication-manager/ux_dck_zpool_loop.json: no such file or directory

2017/08/06 12:03:06 [ux_dck_zpool_loop] TESTI - testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/06 12:03:06 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from  to Suspect
2017/08/06 12:03:06 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/06 12:03:06 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/06 12:03:06 [ux_dck_zpool_loop] STATE - ERR00021 All cluster down in non-interactive mode
2017/08/06 12:03:06 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.71 is down
2017/08/06 12:03:07 [ux_dck_zpool_loop] INFO  - Provisioning delete service 7f7c5393-24b4-4d4c-83ff-da9014a07da6
2017/08/06 12:03:10 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/06 12:03:10 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/06 12:03:12 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/06 12:03:14 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/06 12:03:14 [ux_dck_zpool_loop] INFO  - 10:03:46,095 disk#00        INFO    already provisionned
10:03:46,127 disk#00        INFO    loop /srv/4832677178583133704_docker.dsk is already up
10:03:46,168 disk#0000      INFO    already provisionned
10:03:46,176 disk#0000      INFO    zp4832677178583133704_00 is already up
10:03:46,184 disk#01        INFO    already provisionned
10:03:46,228 disk#01        INFO    loop /srv/4832677178583133704_pod01.dsk is already up
10:03:46,274 disk#1001      INFO    already provisionned
10:03:46,281 disk#1001      INFO    zp4832677178583133704_pod01 is already up
10:03:46,297 fs#00          INFO    /sbin/zfs set refquota=2048M zp4832677178583133704_00/docker
10:03:46,307 fs#00          INFO    provisioned
10:03:46,317 fs#00          INFO    zfs zp4832677178583133704_00/docker@/srv/4832677178583133704/docker is already mounted
10:03:46,334 fs#01          INFO    /sbin/zfs set refquota=1024M zp4832677178583133704_pod01/pod01
10:03:46,346 fs#01          INFO    provisioned
10:03:46,357 fs#01          INFO    zfs zp4832677178583133704_pod01/pod01@/srv/4832677178583133704/pod01 is already mounted
10:03:46,357 fs#01          INFO    /usr/bin/svcmgr -s 4832677178583133704 push service status;/usr/bin/svcmgr -s 4832677178583133704 compliance fix --attach --moduleset mariadb.svc.mrm.db
10:03:48,376 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/4832677178583133704/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/4832677178583133704/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/4832677178583133704/pod01/etc/mysql/compress.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/rc.d/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/threadpool.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tmp/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/aria.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/tokudb.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/aria/ is ok
file /srv/4832677178583133704/pod01/data/.system/repl/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/custom/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/security.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/redo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/semisync.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/audit.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/multidomains.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/my.cnf is ok
file /srv/4832677178583133704/pod01/init/ is ok
file /srv/4832677178583133704/pod01/data/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tokudb/ is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/undo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/innodb.cnf is ok
file /srv/4832677178583133704/pod01/init/launcher is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/ is ok
file /srv/4832677178583133704/pod01/init/start is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/4832677178583133704/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/4832677178583133704/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/logs/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/logs.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logslow.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/network.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.209175
10:03:48,457 container#0001 INFO    container docker container 4832677178583133704.container.0001@busybox:latest already started on node-1-1
10:03:48,501 ip#01          INFO    skip allocate: an ip is already defined
10:03:48,560 ip#01          INFO    192.168.100.70 is already up on br0
10:03:48,699 container#2001 INFO    container docker container 4832677178583133704.container.2001@mariadb:10.2 already started on node-1-1
10:03:48,919                INFO    send /etc/opensvc/4832677178583133704.conf to collector
10:03:48,920                INFO    update /var/lib/opensvc/4832677178583133704/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/06 12:03:16 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:16 [ux_dck_zpool_loop] INFO  - Database started
2017/08/06 12:03:18 [ux_dck_zpool_loop] INFO  - Provisioning delete service 8dd0381d-cbd3-4ec0-833c-dc4abae42e58
2017/08/06 12:03:24 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/06 12:03:27 [ux_dck_zpool_loop] INFO  - 10:03:57,098 disk#00        INFO    already provisionned
10:03:57,163 disk#00        INFO    loop /srv/17311646700765639015_docker.dsk is already up
10:03:57,241 disk#0000      INFO    already provisionned
10:03:57,248 disk#0000      INFO    zp17311646700765639015_00 is already up
10:03:57,256 disk#01        INFO    already provisionned
10:03:57,319 disk#01        INFO    loop /srv/17311646700765639015_pod01.dsk is already up
10:03:57,397 disk#1001      INFO    already provisionned
10:03:57,404 disk#1001      INFO    zp17311646700765639015_pod01 is already up
10:03:57,420 fs#00          INFO    /sbin/zfs set refquota=2048M zp17311646700765639015_00/docker
10:03:57,430 fs#00          INFO    provisioned
10:03:57,440 fs#00          INFO    zfs zp17311646700765639015_00/docker@/srv/17311646700765639015/docker is already mounted
10:03:57,458 fs#01          INFO    /sbin/zfs set refquota=1024M zp17311646700765639015_pod01/pod01
10:03:57,472 fs#01          INFO    provisioned
10:03:57,482 fs#01          INFO    zfs zp17311646700765639015_pod01/pod01@/srv/17311646700765639015/pod01 is already mounted
10:03:57,482 fs#01          INFO    /usr/bin/svcmgr -s 17311646700765639015 push service status;/usr/bin/svcmgr -s 17311646700765639015 compliance fix --attach --moduleset mariadb.svc.mrm.db
10:04:00,044 fs#01          ERROR   command failed with stdout:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf does not exist
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   nok
ACTION:   fixable
STATUS:   n/a
ACTION:   fix
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
ERR: failed to concatenate  to rules list
STATUS:   nok
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf does not exist
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   nok
=================================== digest ===================================
0 n/a
0 passed
1 error
 mariadb.svc.mrm.db.cnf
total duration: 0:00:00.735565
10:04:00,129 container#0001 INFO    container docker container 17311646700765639015.container.0001@busybox:latest already started on node-1-2
10:04:00,170 ip#01          INFO    skip allocate: an ip is already defined
10:04:00,231 ip#01          INFO    192.168.100.71 is already up on br0
10:04:00,380 container#2001 INFO    docker run -d --name=17311646700765639015.container.2001 --net=container:17311646700765639015.container.0001 -e MYSQL_ROOT_PASSWORD=mariadb -e MYSQL_INITDB_SKIP_TZINFO=yes -v /etc/localtime:/etc/localtime:ro -v /srv/17311646700765639015/pod01/data:/var/lib/mysql:rw -v /srv/17311646700765639015/pod01/etc/mysql:/etc/mysql:rw -v /srv/17311646700765639015/pod01/init:/docker-entrypoint-initdb.d:rw --rm --cgroup-parent /17311646700765639015/container.docker/container.2001 mariadb:10.2
10:04:00,589 container#2001 INFO    output:
89893e559624286172a4e1fe962f5149a4da9d8b309f861eae145d5759ca9a46
10:04:00,601 container#2001 INFO    wait for up status
10:04:00,632 container#2001 INFO    wait for container operational
10:04:00,848                INFO    send /etc/opensvc/17311646700765639015.conf to collector
10:04:00,849                INFO    update /var/lib/opensvc/17311646700765639015/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/06 12:03:28 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/06 12:03:29 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:31 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:33 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:35 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:37 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:39 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:41 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:43 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:45 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:47 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:49 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:51 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:53 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:55 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:57 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:03:59 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:01 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:03 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:05 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:07 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:09 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:11 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:13 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:15 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:17 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:19 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:21 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:23 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:25 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:27 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:27 [ux_dck_zpool_loop] INFO  - Database start timeout
2017/08/06 12:04:32 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/06 12:04:33 [ux_dck_zpool_loop] INFO  - 10:05:05,195 disk#00        INFO    already provisionned
10:05:05,259 disk#00        INFO    loop /srv/10940044185188150515_docker.dsk is already up
10:05:05,329 disk#0000      INFO    already provisionned
10:05:05,336 disk#0000      INFO    zp10940044185188150515_00 is already up
10:05:05,344 disk#01        INFO    already provisionned
10:05:05,415 disk#01        INFO    loop /srv/10940044185188150515_pod01.dsk is already up
10:05:05,492 disk#1001      INFO    already provisionned
10:05:05,500 disk#1001      INFO    zp10940044185188150515_pod01 is already up
10:05:05,516 fs#00          INFO    /sbin/zfs set refquota=2048M zp10940044185188150515_00/docker
10:05:05,526 fs#00          INFO    provisioned
10:05:05,536 fs#00          INFO    zfs zp10940044185188150515_00/docker@/srv/10940044185188150515/docker is already mounted
10:05:05,553 fs#01          INFO    /sbin/zfs set refquota=1024M zp10940044185188150515_pod01/pod01
10:05:05,562 fs#01          INFO    provisioned
10:05:05,572 fs#01          INFO    zfs zp10940044185188150515_pod01/pod01@/srv/10940044185188150515/pod01 is already mounted
10:05:05,572 fs#01          INFO    /usr/bin/svcmgr -s 10940044185188150515 push service status;/usr/bin/svcmgr -s 10940044185188150515 compliance fix --attach --moduleset mariadb.svc.mrm.proxy
10:05:07,646 fs#01          INFO    output:
moduleset mariadb.svc.mrm.proxy is already attached to this service
========================= mariadb.svc.mrm.proxy.cnf ==========================
ACTION:   check
file //srv/10940044185188150515/pod01/conf/maxscale.cnf is ok
file /srv/10940044185188150515/pod01/init/launcher is ok
file //srv/10940044185188150515/pod01/log/ is ok
file //srv/10940044185188150515/pod01/data/ is ok
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml is ok
file //srv/10940044185188150515/pod01/init/ is ok
file //srv/10940044185188150515/pod01/conf/ is ok
file //srv/10940044185188150515/pod01/conf/keepalived.conf is ok
file //srv/10940044185188150515/pod01/conf/config.toml is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.proxy.cnf
0 error
total duration: 0:00:00.107792
10:05:07,740 container#0001 INFO    container docker container 10940044185188150515.container.0001@busybox:latest already started on node-1-2
10:05:07,787 ip#01          INFO    skip allocate: an ip is already defined
10:05:07,855 ip#01          INFO    192.168.100.50 is already up on br0
10:05:07,993 container#2001 INFO    container docker container 10940044185188150515.container.2001@asosso/maxscale:latest already started on node-1-2
10:05:08,222                INFO    send /etc/opensvc/10940044185188150515.conf to collector
10:05:08,223                INFO    update /var/lib/opensvc/10940044185188150515/last_pushed_config timestamp

2017/08/06 12:04:34 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/06 12:04:36 [ux_dck_zpool_loop] INFO  - Cleaning up replication on existing servers
2017/08/06 12:04:36 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/06 12:04:46 [ux_dck_zpool_loop] TESTI - testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/06 12:04:48 [ux_dck_zpool_loop] INFO  - Provisioning delete service b961bd79-e1c0-46c2-87e6-c65379a67a1b
2017/08/06 12:04:54 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/06 12:04:55 [ux_dck_zpool_loop] INFO  - 10:05:26,395 disk#00        INFO    already provisionned
10:05:26,428 disk#00        INFO    loop /srv/4832677178583133704_docker.dsk is already up
10:05:26,464 disk#0000      INFO    already provisionned
10:05:26,472 disk#0000      INFO    zp4832677178583133704_00 is already up
10:05:26,480 disk#01        INFO    already provisionned
10:05:26,511 disk#01        INFO    loop /srv/4832677178583133704_pod01.dsk is already up
10:05:26,557 disk#1001      INFO    already provisionned
10:05:26,564 disk#1001      INFO    zp4832677178583133704_pod01 is already up
10:05:26,579 fs#00          INFO    /sbin/zfs set refquota=2048M zp4832677178583133704_00/docker
10:05:26,587 fs#00          INFO    provisioned
10:05:26,597 fs#00          INFO    zfs zp4832677178583133704_00/docker@/srv/4832677178583133704/docker is already mounted
10:05:26,614 fs#01          INFO    /sbin/zfs set refquota=1024M zp4832677178583133704_pod01/pod01
10:05:26,625 fs#01          INFO    provisioned
10:05:26,635 fs#01          INFO    zfs zp4832677178583133704_pod01/pod01@/srv/4832677178583133704/pod01 is already mounted
10:05:26,636 fs#01          INFO    /usr/bin/svcmgr -s 4832677178583133704 push service status;/usr/bin/svcmgr -s 4832677178583133704 compliance fix --attach --moduleset mariadb.svc.mrm.db
10:05:28,780 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/4832677178583133704/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/4832677178583133704/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/4832677178583133704/pod01/etc/mysql/compress.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/rc.d/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/threadpool.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tmp/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/aria.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/tokudb.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/aria/ is ok
file /srv/4832677178583133704/pod01/data/.system/repl/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/custom/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/security.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/redo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/semisync.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/audit.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/multidomains.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/my.cnf is ok
file /srv/4832677178583133704/pod01/init/ is ok
file /srv/4832677178583133704/pod01/data/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tokudb/ is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/undo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/innodb.cnf is ok
file /srv/4832677178583133704/pod01/init/launcher is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/ is ok
file /srv/4832677178583133704/pod01/init/start is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/4832677178583133704/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/4832677178583133704/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/logs/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/logs.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logslow.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/network.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.208301
10:05:28,854 container#0001 INFO    container docker container 4832677178583133704.container.0001@busybox:latest already started on node-1-1
10:05:28,898 ip#01          INFO    skip allocate: an ip is already defined
10:05:28,960 ip#01          INFO    192.168.100.70 is already up on br0
10:05:29,098 container#2001 INFO    container docker container 4832677178583133704.container.2001@mariadb:10.2 already started on node-1-1
10:05:29,324                INFO    send /etc/opensvc/4832677178583133704.conf to collector
10:05:29,324                INFO    update /var/lib/opensvc/4832677178583133704/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/06 12:04:56 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/06 12:04:57 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:04:57 [ux_dck_zpool_loop] INFO  - Database started
2017/08/06 12:04:58 [ux_dck_zpool_loop] INFO  - Provisioning delete service bfb8770e-6f31-471f-8f6e-6bbc3742362e
2017/08/06 12:05:04 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/06 12:05:08 [ux_dck_zpool_loop] INFO  - 10:05:37,438 disk#00        INFO    already provisionned
10:05:37,507 disk#00        INFO    loop /srv/17311646700765639015_docker.dsk is already up
10:05:37,577 disk#0000      INFO    already provisionned
10:05:37,584 disk#0000      INFO    zp17311646700765639015_00 is already up
10:05:37,592 disk#01        INFO    already provisionned
10:05:37,657 disk#01        INFO    loop /srv/17311646700765639015_pod01.dsk is already up
10:05:37,732 disk#1001      INFO    already provisionned
10:05:37,740 disk#1001      INFO    zp17311646700765639015_pod01 is already up
10:05:37,755 fs#00          INFO    /sbin/zfs set refquota=2048M zp17311646700765639015_00/docker
10:05:37,767 fs#00          INFO    provisioned
10:05:37,777 fs#00          INFO    zfs zp17311646700765639015_00/docker@/srv/17311646700765639015/docker is already mounted
10:05:37,794 fs#01          INFO    /sbin/zfs set refquota=1024M zp17311646700765639015_pod01/pod01
10:05:37,805 fs#01          INFO    provisioned
10:05:37,816 fs#01          INFO    zfs zp17311646700765639015_pod01/pod01@/srv/17311646700765639015/pod01 is already mounted
10:05:37,816 fs#01          INFO    /usr/bin/svcmgr -s 17311646700765639015 push service status;/usr/bin/svcmgr -s 17311646700765639015 compliance fix --attach --moduleset mariadb.svc.mrm.db
10:05:40,432 fs#01          ERROR   command failed with stdout:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf does not exist
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   nok
ACTION:   fixable
STATUS:   n/a
ACTION:   fix
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
ERR: failed to concatenate  to rules list
STATUS:   nok
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
ERR: symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf does not exist
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   nok
=================================== digest ===================================
0 n/a
0 passed
1 error
 mariadb.svc.mrm.db.cnf
total duration: 0:00:00.738672
10:05:40,511 container#0001 INFO    container docker container 17311646700765639015.container.0001@busybox:latest already started on node-1-2
10:05:40,555 ip#01          INFO    skip allocate: an ip is already defined
10:05:40,629 ip#01          INFO    192.168.100.71 is already up on br0
10:05:40,768 container#2001 INFO    docker run -d --name=17311646700765639015.container.2001 --net=container:17311646700765639015.container.0001 -e MYSQL_ROOT_PASSWORD=mariadb -e MYSQL_INITDB_SKIP_TZINFO=yes -v /etc/localtime:/etc/localtime:ro -v /srv/17311646700765639015/pod01/data:/var/lib/mysql:rw -v /srv/17311646700765639015/pod01/etc/mysql:/etc/mysql:rw -v /srv/17311646700765639015/pod01/init:/docker-entrypoint-initdb.d:rw --rm --cgroup-parent /17311646700765639015/container.docker/container.2001 mariadb:10.2
10:05:40,945 container#2001 INFO    output:
b41547dfbebe9921dad976be9ac39371a7ead88dc3c31336eff0fe1861f1cf7d
10:05:40,967 container#2001 INFO    wait for up status
10:05:40,992 container#2001 INFO    wait for container operational
10:05:41,230                INFO    send /etc/opensvc/17311646700765639015.conf to collector
10:05:41,231                INFO    update /var/lib/opensvc/17311646700765639015/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/06 12:05:08 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/06 12:05:10 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:12 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:14 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:16 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:18 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:20 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:22 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:24 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:26 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:28 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:30 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:32 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:34 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:36 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:38 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:40 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:42 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:44 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:46 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:48 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:50 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:52 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:54 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:56 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:05:58 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:06:00 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:06:02 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:06:04 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:06:06 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:06:08 [ux_dck_zpool_loop] INFO  - Waiting for database start
2017/08/06 12:06:08 [ux_dck_zpool_loop] INFO  - Database start timeout
2017/08/06 12:06:12 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/06 12:06:14 [ux_dck_zpool_loop] INFO  - 10:06:45,498 disk#00        INFO    already provisionned
10:06:45,572 disk#00        INFO    loop /srv/10940044185188150515_docker.dsk is already up
10:06:45,648 disk#0000      INFO    already provisionned
10:06:45,655 disk#0000      INFO    zp10940044185188150515_00 is already up
10:06:45,663 disk#01        INFO    already provisionned
10:06:45,727 disk#01        INFO    loop /srv/10940044185188150515_pod01.dsk is already up
10:06:45,805 disk#1001      INFO    already provisionned
10:06:45,812 disk#1001      INFO    zp10940044185188150515_pod01 is already up
10:06:45,828 fs#00          INFO    /sbin/zfs set refquota=2048M zp10940044185188150515_00/docker
10:06:45,839 fs#00          INFO    provisioned
10:06:45,850 fs#00          INFO    zfs zp10940044185188150515_00/docker@/srv/10940044185188150515/docker is already mounted
10:06:45,869 fs#01          INFO    /sbin/zfs set refquota=1024M zp10940044185188150515_pod01/pod01
10:06:45,884 fs#01          INFO    provisioned
10:06:45,894 fs#01          INFO    zfs zp10940044185188150515_pod01/pod01@/srv/10940044185188150515/pod01 is already mounted
10:06:45,895 fs#01          INFO    /usr/bin/svcmgr -s 10940044185188150515 push service status;/usr/bin/svcmgr -s 10940044185188150515 compliance fix --attach --moduleset mariadb.svc.mrm.proxy
10:06:47,949 fs#01          INFO    output:
moduleset mariadb.svc.mrm.proxy is already attached to this service
========================= mariadb.svc.mrm.proxy.cnf ==========================
ACTION:   check
file //srv/10940044185188150515/pod01/conf/maxscale.cnf is ok
file /srv/10940044185188150515/pod01/init/launcher is ok
file //srv/10940044185188150515/pod01/log/ is ok
file //srv/10940044185188150515/pod01/data/ is ok
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml is ok
file //srv/10940044185188150515/pod01/init/ is ok
file //srv/10940044185188150515/pod01/conf/ is ok
file //srv/10940044185188150515/pod01/conf/keepalived.conf is ok
file //srv/10940044185188150515/pod01/conf/config.toml is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.proxy.cnf
0 error
total duration: 0:00:00.107635
10:06:48,028 container#0001 INFO    container docker container 10940044185188150515.container.0001@busybox:latest already started on node-1-2
10:06:48,072 ip#01          INFO    skip allocate: an ip is already defined
10:06:48,145 ip#01          INFO    192.168.100.50 is already up on br0
10:06:48,284 container#2001 INFO    container docker container 10940044185188150515.container.2001@asosso/maxscale:latest already started on node-1-2
10:06:48,502                INFO    send /etc/opensvc/10940044185188150515.conf to collector
10:06:48,503                INFO    update /var/lib/opensvc/10940044185188150515/last_pushed_config timestamp

2017/08/06 12:06:14 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/06 12:06:17 [ux_dck_zpool_loop] INFO  - Cleaning up replication on existing servers
2017/08/06 12:06:17 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:48:30 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71 [192.168.100.70 192.168.100.71]
2017/08/07 21:48:30 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/07 21:48:30 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/07 21:48:30 [ux_dck_zpool_loop] INFO  - Failover in automatic mode
2017/08/07 21:48:30 [ux_dck_zpool_loop] WARN  - File error: open /var/lib/replication-manager/ux_dck_zpool_loop.json: no such file or directory

2017/08/07 21:48:32 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from  to Suspect
2017/08/07 21:48:32 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.71 is down
2017/08/07 21:48:32 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/07 21:48:32 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/07 21:48:32 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/07 21:48:36 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/07 21:48:36 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/07 21:48:37 [ux_dck_zpool_loop] TESTI - testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/07 21:48:39 [ux_dck_zpool_loop] INFO  - Provisioning delete service 2949af14-e119-4815-a215-33fa5e0b8e75
2017/08/07 21:48:46 [ux_dck_zpool_loop] INFO  - 19:48:43,214 disk#00        INFO    already provisionned
19:48:43,250 disk#00        INFO    loop /srv/4832677178583133704_docker.dsk is already up
19:48:43,295 disk#0000      INFO    already provisionned
19:48:43,302 disk#0000      INFO    zp4832677178583133704_00 is already up
19:48:43,309 disk#01        INFO    already provisionned
19:48:43,346 disk#01        INFO    loop /srv/4832677178583133704_pod01.dsk is already up
19:48:43,387 disk#1001      INFO    already provisionned
19:48:43,394 disk#1001      INFO    zp4832677178583133704_pod01 is already up
19:48:43,408 fs#00          INFO    /sbin/zfs set refquota=2048M zp4832677178583133704_00/docker
19:48:43,416 fs#00          INFO    provisioned
19:48:43,426 fs#00          INFO    zfs zp4832677178583133704_00/docker@/srv/4832677178583133704/docker is already mounted
19:48:43,441 fs#01          INFO    /sbin/zfs set refquota=1024M zp4832677178583133704_pod01/pod01
19:48:43,451 fs#01          INFO    provisioned
19:48:43,461 fs#01          INFO    zfs zp4832677178583133704_pod01/pod01@/srv/4832677178583133704/pod01 is already mounted
19:48:43,461 fs#01          INFO    /usr/bin/svcmgr -s 4832677178583133704 push service status;/usr/bin/svcmgr -s 4832677178583133704 compliance fix --attach --moduleset mariadb.svc.mrm.db
19:48:45,572 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/4832677178583133704/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/4832677178583133704/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/4832677178583133704/pod01/etc/mysql/compress.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/rc.d/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/threadpool.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tmp/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/aria.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/tokudb.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/aria/ is ok
file /srv/4832677178583133704/pod01/data/.system/repl/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/custom/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/security.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/redo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/semisync.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/audit.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/multidomains.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/my.cnf is ok
file /srv/4832677178583133704/pod01/init/ is ok
file /srv/4832677178583133704/pod01/data/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tokudb/ is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/undo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/innodb.cnf is ok
file /srv/4832677178583133704/pod01/init/launcher is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/ is ok
file /srv/4832677178583133704/pod01/init/start is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/4832677178583133704/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/4832677178583133704/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/logs/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/logs.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logslow.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/network.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.208486
19:48:45,647 container#0001 INFO    container docker container 4832677178583133704.container.0001@busybox:latest already started on node-1-1
19:48:45,689 ip#01          INFO    skip allocate: an ip is already defined
19:48:45,746 ip#01          INFO    192.168.100.70 is already up on br0
19:48:45,884 container#2001 INFO    container docker container 4832677178583133704.container.2001@mariadb:10.2 already started on node-1-1
19:48:46,100                INFO    send /etc/opensvc/4832677178583133704.conf to collector
19:48:46,101                INFO    update /var/lib/opensvc/4832677178583133704/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/07 21:48:48 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:48:48 [ux_dck_zpool_loop] INFO  - Waiting for database start 192.168.100.70
2017/08/07 21:48:48 [ux_dck_zpool_loop] INFO  - Database started
2017/08/07 21:48:50 [ux_dck_zpool_loop] INFO  - Provisioning delete service 72c4e82f-189d-4a33-aad1-edde9925a3d7
2017/08/07 21:48:52 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/07 21:48:54 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:48:54 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/07 21:48:58 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:49:04 [ux_dck_zpool_loop] INFO  - 19:48:53,279 disk#00        INFO    already provisionned
19:48:53,317 disk#00        INFO    /sbin/losetup -f /srv/17311646700765639015_docker.dsk
19:48:53,389 disk#00        INFO    /dev/loop0 now loops to /srv/17311646700765639015_docker.dsk
19:48:53,447 disk#0000      INFO    zpool create -m legacy zp17311646700765639015_00 /srv/17311646700765639015_docker.dsk
19:48:53,451 disk#0000      ERROR   stderr:
invalid vdev specification
use '-f' to override the following errors:
/srv/17311646700765639015_docker.dsk is part of exported pool 'zp17311646700765639015_00'
19:48:53,452 disk#0000      INFO    provisioned
19:48:53,455 disk#0000      INFO    zpool import -f -o cachefile=/var/lib/opensvc/zpool.cache zp17311646700765639015_00
19:48:53,901 disk#01        INFO    already provisionned
19:48:53,962 disk#01        INFO    /sbin/losetup -f /srv/17311646700765639015_pod01.dsk
19:48:54,073 disk#01        INFO    /dev/loop1 now loops to /srv/17311646700765639015_pod01.dsk
19:48:54,154 disk#1001      INFO    zpool create -m legacy zp17311646700765639015_pod01 /srv/17311646700765639015_pod01.dsk
19:48:54,158 disk#1001      ERROR   stderr:
invalid vdev specification
use '-f' to override the following errors:
/srv/17311646700765639015_pod01.dsk is part of exported pool 'zp17311646700765639015_pod01'
19:48:54,159 disk#1001      INFO    provisioned
19:48:54,162 disk#1001      INFO    zpool import -f -o cachefile=/var/lib/opensvc/zpool.cache zp17311646700765639015_pod01
19:48:54,652 fs#00          INFO    /sbin/zfs set refquota=2048M zp17311646700765639015_00/docker
19:48:54,661 fs#00          INFO    provisioned
19:48:54,678 fs#00          INFO    /sbin/zfs mount zp17311646700765639015_00/docker
19:48:54,712 fs#01          INFO    /sbin/zfs set refquota=1024M zp17311646700765639015_pod01/pod01
19:48:54,720 fs#01          INFO    provisioned
19:48:54,740 fs#01          INFO    /sbin/zfs mount zp17311646700765639015_pod01/pod01
19:48:54,753 fs#01          INFO    /usr/bin/svcmgr -s 17311646700765639015 push service status;/usr/bin/svcmgr -s 17311646700765639015 compliance fix --attach --moduleset mariadb.svc.mrm.db
19:48:56,823 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.208869
19:48:56,907 container#0001 INFO    docker start 83c9084e17f7480d19a674f489d0f06de582c125eae653481663682c891a577c
19:48:57,093 container#0001 INFO    output:
83c9084e17f7480d19a674f489d0f06de582c125eae653481663682c891a577c
19:48:57,106 container#0001 INFO    wait for up status
19:48:57,135 container#0001 INFO    wait for container operational
19:48:57,178 ip#01          INFO    skip allocate: an ip is already defined
19:48:57,250 ip#01          INFO    checking 192.168.100.71 availability
19:49:00,323 ip#01          INFO    bridge mode
19:49:00,353 ip#01          INFO    create symlink /var/run/netns/24077 -> /proc/24077/ns/net
19:49:00,422 ip#01          INFO    /sbin/ip link add name veth1pl24077 mtu 1500 type veth peer name veth1pg24077 mtu 1500
19:49:00,428 ip#01          INFO    /sbin/ip link set veth1pl24077 master br0
19:49:00,432 ip#01          INFO    /sbin/ip link set veth1pl24077 up
19:49:00,435 ip#01          INFO    /sbin/ip link set veth1pg24077 netns 24077
19:49:00,454 ip#01          INFO    /sbin/ip netns exec 24077 ip link set veth1pg24077 name eth1
19:49:00,509 ip#01          INFO    /sbin/ip netns exec 24077 ip addr add 192.168.100.71/24 dev eth1
19:49:00,593 ip#01          INFO    /sbin/ip netns exec 24077 ip link set eth1 up
19:49:00,637 ip#01          INFO    /sbin/ip netns exec 24077 ip route replace default via 192.168.100.254
19:49:00,682 ip#01          INFO    remove /var/run/netns/24077
19:49:00,821 container#2001 INFO    docker run -d --name=17311646700765639015.container.2001 --net=container:17311646700765639015.container.0001 -e MYSQL_ROOT_PASSWORD=mariadb -e MYSQL_INITDB_SKIP_TZINFO=yes -v /etc/localtime:/etc/localtime:ro -v /srv/17311646700765639015/pod01/data:/var/lib/mysql:rw -v /srv/17311646700765639015/pod01/etc/mysql:/etc/mysql:rw -v /srv/17311646700765639015/pod01/init:/docker-entrypoint-initdb.d:rw --rm --cgroup-parent /17311646700765639015/container.docker/container.2001 mariadb:10.2
19:49:01,067 container#2001 INFO    output:
0888701b22da521ecf541bab4045a2517a669ade7a6c7011c6c25c4a4c9d5377
19:49:01,083 container#2001 INFO    wait for up status
19:49:01,110 container#2001 INFO    wait for container operational
19:49:01,334                INFO    send /etc/opensvc/17311646700765639015.conf to collector
19:49:01,335                INFO    update /var/lib/opensvc/17311646700765639015/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/07 21:49:06 [ux_dck_zpool_loop] INFO  - Waiting for database start 192.168.100.71
2017/08/07 21:49:06 [ux_dck_zpool_loop] INFO  - Database started
2017/08/07 21:49:12 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.50 3307
2017/08/07 21:49:12 [ux_dck_zpool_loop] ERROR - Could not connect to MaxScale:Connection failed to address 192.168.100.50:3307
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster db servers down
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - INF00001 CLOSING Server 192.168.100.71 is down
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Connection failed to address 192.168.100.50:3307
2017/08/07 21:49:12 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:49:14 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/07 21:49:14 [ux_dck_zpool_loop] INFO  - 19:49:09,290 disk#00        INFO    already provisionned
19:49:09,357 disk#00        INFO    loop /srv/10940044185188150515_docker.dsk is already up
19:49:09,435 disk#0000      INFO    already provisionned
19:49:09,444 disk#0000      INFO    zp10940044185188150515_00 is already up
19:49:09,452 disk#01        INFO    already provisionned
19:49:09,525 disk#01        INFO    loop /srv/10940044185188150515_pod01.dsk is already up
19:49:09,602 disk#1001      INFO    already provisionned
19:49:09,610 disk#1001      INFO    zp10940044185188150515_pod01 is already up
19:49:09,625 fs#00          INFO    /sbin/zfs set refquota=2048M zp10940044185188150515_00/docker
19:49:09,634 fs#00          INFO    provisioned
19:49:09,644 fs#00          INFO    zfs zp10940044185188150515_00/docker@/srv/10940044185188150515/docker is already mounted
19:49:09,663 fs#01          INFO    /sbin/zfs set refquota=1024M zp10940044185188150515_pod01/pod01
19:49:09,671 fs#01          INFO    provisioned
19:49:09,681 fs#01          INFO    zfs zp10940044185188150515_pod01/pod01@/srv/10940044185188150515/pod01 is already mounted
19:49:09,682 fs#01          INFO    /usr/bin/svcmgr -s 10940044185188150515 push service status;/usr/bin/svcmgr -s 10940044185188150515 compliance fix --attach --moduleset mariadb.svc.mrm.proxy
19:49:12,180 fs#01          INFO    output:
moduleset mariadb.svc.mrm.proxy is already attached to this service
========================= mariadb.svc.mrm.proxy.cnf ==========================
ACTION:   check
ERR: file //srv/10940044185188150515/pod01/conf/maxscale.cnf does not exist
ERR: file /srv/10940044185188150515/pod01/init/launcher does not exist
ERR: file //srv/10940044185188150515/pod01/log/ does not exist
ERR: file //srv/10940044185188150515/pod01/data/ does not exist
ERR: file //srv/10940044185188150515/pod01/conf/config-haproxy.toml does not exist
ERR: file //srv/10940044185188150515/pod01/init/ does not exist
ERR: file //srv/10940044185188150515/pod01/conf/ mode should be 775 but is 755
ERR: file //srv/10940044185188150515/pod01/conf/ uid should be 999 but is 0
ERR: file //srv/10940044185188150515/pod01/conf/ gid should be 999 but is 0
ERR: file //srv/10940044185188150515/pod01/conf/keepalived.conf does not exist
ERR: file //srv/10940044185188150515/pod01/conf/config.toml does not exist
STATUS:   nok
ACTION:   fixable
STATUS:   n/a
ACTION:   fix
file //srv/10940044185188150515/pod01/conf/maxscale.cnf rewritten
file //srv/10940044185188150515/pod01/conf/maxscale.cnf mode set to 775
file //srv/10940044185188150515/pod01/conf/maxscale.cnf ownership set to 999:999
file: mkdir /srv/10940044185188150515/pod01/init
file /srv/10940044185188150515/pod01/init/launcher rewritten
file /srv/10940044185188150515/pod01/init/launcher mode set to 755
file /srv/10940044185188150515/pod01/init/launcher ownership set to 999:999
file: mkdir //srv/10940044185188150515/pod01/log/
file //srv/10940044185188150515/pod01/log/ mode set to 775
file //srv/10940044185188150515/pod01/log/ ownership set to 999:999
file: mkdir //srv/10940044185188150515/pod01/data/
file //srv/10940044185188150515/pod01/data/ mode set to 775
file //srv/10940044185188150515/pod01/data/ ownership set to 999:999
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml rewritten
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml mode set to 775
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml ownership set to 999:999
file //srv/10940044185188150515/pod01/init/ mode set to 775
file //srv/10940044185188150515/pod01/conf/ mode set to 775
file //srv/10940044185188150515/pod01/conf/ ownership set to 999:999
file //srv/10940044185188150515/pod01/conf/keepalived.conf rewritten
file //srv/10940044185188150515/pod01/conf/keepalived.conf mode set to 775
file //srv/10940044185188150515/pod01/conf/keepalived.conf ownership set to 999:999
file //srv/10940044185188150515/pod01/conf/config.toml rewritten
file //srv/10940044185188150515/pod01/conf/config.toml mode set to 775
file //srv/10940044185188150515/pod01/conf/config.toml ownership set to 999:999
STATUS:   ok
ACTION:   check
file //srv/10940044185188150515/pod01/conf/maxscale.cnf is ok
file /srv/10940044185188150515/pod01/init/launcher is ok
file //srv/10940044185188150515/pod01/log/ is ok
file //srv/10940044185188150515/pod01/data/ is ok
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml is ok
file //srv/10940044185188150515/pod01/init/ is ok
file //srv/10940044185188150515/pod01/conf/ is ok
file //srv/10940044185188150515/pod01/conf/keepalived.conf is ok
file //srv/10940044185188150515/pod01/conf/config.toml is ok
STATUS:   ok
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.proxy.cnf
0 error
total duration: 0:00:00.428504
19:49:12,328 container#0001 INFO    container docker container 10940044185188150515.container.0001@busybox:latest already started on node-1-2
19:49:12,380 ip#01          INFO    skip allocate: an ip is already defined
19:49:12,445 ip#01          INFO    192.168.100.50 is already up on br0
19:49:12,582 container#2001 INFO    docker run -d --name=10940044185188150515.container.2001 --net=container:10940044185188150515.container.0001 -v /etc/localtime:/etc/localtime:ro -v /srv/10940044185188150515/pod01/conf:/etc/maxscale.d:rw --rm --cgroup-parent /10940044185188150515/container.docker/container.2001 asosso/maxscale:latest
19:49:12,806 container#2001 INFO    output:
708fd62e63673e4405debb1c3267371cb94e163b21e146365a042e7e0cc5c333
19:49:12,821 container#2001 INFO    wait for up status
19:49:12,850 container#2001 INFO    wait for container operational
19:49:13,101                INFO    send /etc/opensvc/10940044185188150515.conf to collector
19:49:13,102                INFO    update /var/lib/opensvc/10940044185188150515/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/07 21:49:17 [ux_dck_zpool_loop] INFO  - Cleaning up replication on existing servers
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/07 21:49:19 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/07 21:49:27 [ux_dck_zpool_loop] INFO  - Environment bootstrapped with 192.168.100.70 as master
2017/08/07 21:49:27 [ux_dck_zpool_loop] INFO  - Waiting Bootstrap and discovery
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster db servers down
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:49:28 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/07 21:49:29 [ux_dck_zpool_loop] INFO  - Waiting Bootstrap and discovery
2017/08/07 21:49:29 [ux_dck_zpool_loop] INFO  - Cluster is Bootstraped and discovery
2017/08/07 21:49:29 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.50 3307
2017/08/07 21:49:29 [ux_dck_zpool_loop] ERROR - Could not connect to MaxScale:Connection failed to address 192.168.100.50:3307
2017/08/07 21:49:29 [ux_dck_zpool_loop] INFO  - Waiting for cluster start
2017/08/07 21:49:32 [ux_dck_zpool_loop] INFO  - Waiting for cluster start
2017/08/07 21:49:32 [ux_dck_zpool_loop] INFO  - Cluster was started
2017/08/07 21:49:32 [ux_dck_zpool_loop] INFO  - Starting Test testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/07 21:49:32 [ux_dck_zpool_loop] BENCH - PreparedExecConcurrent2 10 iterations
 42.250623ms 	    237 queries/sec	    8 allocs/query	    784 B/query

Finished... Total running time: 57.499457ms

2017/08/07 21:49:34 [ux_dck_zpool_loop] STATE - ERR00018 CLOSING Could not connect to MaxScale: Connection failed to address 192.168.100.50:3307
2017/08/07 21:49:40 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Slave to Suspect
2017/08/07 21:49:40 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:49:40 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:49:40 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:49:40 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.71 is down
2017/08/07 21:49:40 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/07 21:49:47 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/07 21:49:47 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/07 21:50:01 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 1/3
2017/08/07 21:50:01 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from StandAlone to Suspect
2017/08/07 21:50:05 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:50:05 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:50:06 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 2/3
2017/08/07 21:50:09 [ux_dck_zpool_loop] INFO  - Starting Database service 17311646700765639015
2017/08/07 21:50:10 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/07 21:50:10 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/07 21:50:11 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.70 as failed
2017/08/07 21:50:11 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Suspect to Failed
2017/08/07 21:50:11 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:13 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:15 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:17 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:19 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/07 21:50:19 [ux_dck_zpool_loop] ERROR - Slave wants to rejoin non discovered master
2017/08/07 21:50:19 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:21 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:23 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster db servers down
2017/08/07 21:50:23 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:50:23 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/07 21:50:23 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/07 21:50:23 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:25 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:27 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:29 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:31 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:33 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:35 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:37 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:39 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:41 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:43 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:45 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:47 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:49 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:51 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:53 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:55 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:57 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:50:59 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:01 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:03 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:05 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:07 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:09 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:09 [ux_dck_zpool_loop] ERROR - Rejoin timeout
2017/08/07 21:51:14 [ux_dck_zpool_loop] INFO  - Starting Database service 4832677178583133704
2017/08/07 21:51:16 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:18 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:20 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:22 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:24 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:24 [ux_dck_zpool_loop] INFO  - Trying to rejoin restarted server 192.168.100.70
2017/08/07 21:51:24 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/07 21:51:24 [ux_dck_zpool_loop] STATE - INF00001 CLOSING Server 192.168.100.70 is down
2017/08/07 21:51:24 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/07 21:51:24 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/07 21:51:26 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:28 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:30 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:32 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:34 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:36 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:38 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:40 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:42 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:44 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:46 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:48 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:50 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:52 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:54 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:56 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:51:58 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:00 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:02 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:04 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:06 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:08 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:10 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:12 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:14 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/07 21:52:14 [ux_dck_zpool_loop] ERROR - Rejoin timeout
2017/08/07 21:52:29 [ux_dck_zpool_loop] INFO  - Checksum master table replication_manager_schema.bench =  4134263539 192.168.100.70
2017/08/07 21:52:29 [ux_dck_zpool_loop] INFO  - Number of rows master table replication_manager_schema.bench = 1 192.168.100.70
2017/08/07 21:52:29 [ux_dck_zpool_loop] INFO  - Max Value in bench table replication_manager_schema.bench = 11 192.168.100.70
2017/08/07 21:52:29 [ux_dck_zpool_loop] INFO  - Checksum slave table replication_manager_schema.bench = 4134263539 on 192.168.100.71 
2017/08/07 21:52:29 [ux_dck_zpool_loop] INFO  - Number of rows slave table replication_manager_schema.bench =  1 192.168.100.71
2017/08/07 21:52:29 [ux_dck_zpool_loop] INFO  - Max Value in bench table replication_manager_schema.bench = 11 192.168.100.71
2017/08/07 21:52:30 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:30 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:30 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:30 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:30 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:30 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:30 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:32 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:32 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:32 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:32 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:32 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:32 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:32 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:32 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:35 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:35 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:35 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:35 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:35 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:35 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:35 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:35 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:35 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:37 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:37 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:37 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:37 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:37 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:37 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:37 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:37 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:37 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:39 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:39 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:39 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:39 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:39 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:39 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:39 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:39 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:39 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:41 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:41 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:41 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:41 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:41 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:41 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:41 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:41 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:41 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:43 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:43 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:43 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:43 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:43 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:43 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:43 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:43 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:43 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:45 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:45 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:45 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:45 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:45 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:45 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:45 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:45 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:45 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:47 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:50 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:50 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:52:51 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:52 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:52 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:53 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:54 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:54 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:52:55 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:56 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:52:56 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:57 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:52:58 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:52:58 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:52:59 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:00 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:00 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:01 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:02 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:02 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:03 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:04 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:04 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:05 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:06 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:06 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:07 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:08 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:08 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:09 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:10 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:10 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:11 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:12 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:12 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:13 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:14 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:14 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:15 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:16 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:16 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:17 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:18 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:18 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:19 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/07 21:53:20 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71 [192.168.100.70 192.168.100.71]
2017/08/07 21:53:20 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/07 21:53:20 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/07 21:53:20 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/07 21:53:20 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/07 21:53:20 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from  to Suspect
2017/08/07 21:53:21 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from  to Suspect
2017/08/07 21:53:22 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:24 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:25 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/07 21:53:25 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/07 21:53:25 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/07 21:53:25 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/07 21:53:26 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:28 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:29 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.70 as failed
2017/08/07 21:53:29 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Suspect to Failed
2017/08/07 21:53:30 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:30 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/07 21:53:30 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/07 21:53:32 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:34 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:36 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:38 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:40 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:42 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:44 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:46 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:48 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:50 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/07 21:53:50 [ux_dck_zpool_loop] INFO  - Cluster is shutdown
2017/08/07 21:53:50 [ux_dck_zpool_loop] TEST  - Result FailoverSemisyncAutoRejoinSafeMSMXXXRXSMS                -> {testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS PASS ././config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/replication-manager.conf {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/1.1.0-preview3-101-g480629e/testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=true)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=1) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.50 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=false) unknown %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1,node-1-2 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254 docker node-1-2 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/replication-manager.conf} {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/1.1.0-preview3-101-g480629e/testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.50 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=false) master-slave %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1,node-1-2 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254 docker node-1-2 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/replication-manager.conf}}
2017/08/08 15:00:51 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71 [192.168.100.70 192.168.100.71]
2017/08/08 15:00:51 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/08 15:00:51 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/08 15:00:51 [ux_dck_zpool_loop] INFO  - Failover in automatic mode
2017/08/08 15:00:51 [ux_dck_zpool_loop] WARN  - File error: open /var/lib/replication-manager/ux_dck_zpool_loop.json: no such file or directory

2017/08/08 15:00:54 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from  to Suspect
2017/08/08 15:00:56 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.71 is down
2017/08/08 15:00:56 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/08 15:00:56 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/08 15:00:56 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/08 15:00:57 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/08 15:00:57 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/08 15:00:58 [ux_dck_zpool_loop] TESTI - testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/08 15:01:00 [ux_dck_zpool_loop] INFO  - Provisioning delete service 3640f8ad-06bc-4ee8-9c7f-cfdcc0640146
2017/08/08 15:01:05 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:01:07 [ux_dck_zpool_loop] INFO  - 13:01:02,928 disk#00        INFO    already provisionned
13:01:02,965 disk#00        INFO    loop /srv/4832677178583133704_docker.dsk is already up
13:01:03,010 disk#0000      INFO    already provisionned
13:01:03,018 disk#0000      INFO    zp4832677178583133704_00 is already up
13:01:03,026 disk#01        INFO    already provisionned
13:01:03,057 disk#01        INFO    loop /srv/4832677178583133704_pod01.dsk is already up
13:01:03,094 disk#1001      INFO    already provisionned
13:01:03,101 disk#1001      INFO    zp4832677178583133704_pod01 is already up
13:01:03,116 fs#00          INFO    /sbin/zfs set refquota=2048M zp4832677178583133704_00/docker
13:01:03,125 fs#00          INFO    provisioned
13:01:03,134 fs#00          INFO    zfs zp4832677178583133704_00/docker@/srv/4832677178583133704/docker is already mounted
13:01:03,149 fs#01          INFO    /sbin/zfs set refquota=1024M zp4832677178583133704_pod01/pod01
13:01:03,159 fs#01          INFO    provisioned
13:01:03,170 fs#01          INFO    zfs zp4832677178583133704_pod01/pod01@/srv/4832677178583133704/pod01 is already mounted
13:01:03,170 fs#01          INFO    /usr/bin/svcmgr -s 4832677178583133704 push service status;/usr/bin/svcmgr -s 4832677178583133704 compliance fix --attach --moduleset mariadb.svc.mrm.db
13:01:05,418 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/4832677178583133704/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/4832677178583133704/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/4832677178583133704/pod01/etc/mysql/compress.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/rc.d/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/threadpool.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tmp/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/aria.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/tokudb.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/aria/ is ok
file /srv/4832677178583133704/pod01/data/.system/repl/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/custom/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/security.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/redo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/semisync.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/audit.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/multidomains.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/my.cnf is ok
file /srv/4832677178583133704/pod01/init/ is ok
file /srv/4832677178583133704/pod01/data/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/tokudb/ is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/undo/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/innodb.cnf is ok
file /srv/4832677178583133704/pod01/init/launcher is ok
file /srv/4832677178583133704/pod01/data/.system/innodb/ is ok
file /srv/4832677178583133704/pod01/init/start is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/optimizer.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/4832677178583133704/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/4832677178583133704/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/4832677178583133704/pod01/data/.system/logs/ is ok
file /srv/4832677178583133704/pod01/etc/mysql/logs.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/logslow.cnf is ok
file /srv/4832677178583133704/pod01/etc/mysql/network.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/4832677178583133704/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.208585
13:01:05,493 container#0001 INFO    container docker container 4832677178583133704.container.0001@busybox:latest already started on node-1-1
13:01:05,538 ip#01          INFO    skip allocate: an ip is already defined
13:01:05,615 ip#01          INFO    192.168.100.70 is already up on br0
13:01:05,749 container#2001 INFO    container docker container 4832677178583133704.container.2001@mariadb:10.2 already started on node-1-1
13:01:05,974                INFO    send /etc/opensvc/4832677178583133704.conf to collector
13:01:05,975                INFO    update /var/lib/opensvc/4832677178583133704/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/08 15:01:07 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/08 15:01:09 [ux_dck_zpool_loop] INFO  - Waiting for database start 192.168.100.70
2017/08/08 15:01:09 [ux_dck_zpool_loop] INFO  - Database started
2017/08/08 15:01:10 [ux_dck_zpool_loop] INFO  - Provisioning delete service e83d0afd-598d-4a25-b9df-672d9d6fc72c
2017/08/08 15:01:15 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:01:24 [ux_dck_zpool_loop] INFO  - 13:01:13,939 disk#00        INFO    already provisionned
13:01:13,974 disk#00        INFO    /sbin/losetup -f /srv/17311646700765639015_docker.dsk
13:01:14,050 disk#00        INFO    /dev/loop0 now loops to /srv/17311646700765639015_docker.dsk
13:01:14,112 disk#0000      INFO    zpool create -m legacy zp17311646700765639015_00 /srv/17311646700765639015_docker.dsk
13:01:14,116 disk#0000      ERROR   stderr:
invalid vdev specification
use '-f' to override the following errors:
/srv/17311646700765639015_docker.dsk is part of exported pool 'zp17311646700765639015_00'
13:01:14,116 disk#0000      INFO    provisioned
13:01:14,119 disk#0000      INFO    zpool import -f -o cachefile=/var/lib/opensvc/zpool.cache zp17311646700765639015_00
13:01:14,539 disk#01        INFO    already provisionned
13:01:14,598 disk#01        INFO    /sbin/losetup -f /srv/17311646700765639015_pod01.dsk
13:01:14,710 disk#01        INFO    /dev/loop1 now loops to /srv/17311646700765639015_pod01.dsk
13:01:14,784 disk#1001      INFO    zpool create -m legacy zp17311646700765639015_pod01 /srv/17311646700765639015_pod01.dsk
13:01:14,788 disk#1001      ERROR   stderr:
invalid vdev specification
use '-f' to override the following errors:
/srv/17311646700765639015_pod01.dsk is part of exported pool 'zp17311646700765639015_pod01'
13:01:14,788 disk#1001      INFO    provisioned
13:01:14,791 disk#1001      INFO    zpool import -f -o cachefile=/var/lib/opensvc/zpool.cache zp17311646700765639015_pod01
13:01:15,236 fs#00          INFO    /sbin/zfs set refquota=2048M zp17311646700765639015_00/docker
13:01:15,245 fs#00          INFO    provisioned
13:01:15,262 fs#00          INFO    /sbin/zfs mount zp17311646700765639015_00/docker
13:01:15,292 fs#01          INFO    /sbin/zfs set refquota=1024M zp17311646700765639015_pod01/pod01
13:01:15,301 fs#01          INFO    provisioned
13:01:15,318 fs#01          INFO    /sbin/zfs mount zp17311646700765639015_pod01/pod01
13:01:15,330 fs#01          INFO    /usr/bin/svcmgr -s 17311646700765639015 push service status;/usr/bin/svcmgr -s 17311646700765639015 compliance fix --attach --moduleset mariadb.svc.mrm.db
13:01:17,501 fs#01          INFO    output:
moduleset mariadb.svc.mrm.db attached
=========================== mariadb.svc.mrm.db.cnf ===========================
ACTION:   check
file /srv/17311646700765639015/pod01/etc/mysql/spider.cnf is ok
ERR: OSVC_COMP_DB_CNF_WSREP undefined substitution variable: GCOMM
file /srv/17311646700765639015/pod01/etc/mysql/myrock.cnf is ok
ERR: failed to concatenate  to rules list
file /srv/17311646700765639015/pod01/etc/mysql/compress.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/rc.d/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/threadpool.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tmp/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/aria.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/tokudb.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/noquerycache.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/mysqlgtid.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/aria/ is ok
file /srv/17311646700765639015/pod01/data/.system/repl/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/loggeneral.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/custom/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/security.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/redo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/nomogslaveupdates.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/semisync.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/audit.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/multidomains.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/my.cnf is ok
file /srv/17311646700765639015/pod01/init/ is ok
file /srv/17311646700765639015/pod01/data/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/rpl_ptr.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/tokudb/ is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/undo/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/innodb.cnf is ok
file /srv/17311646700765639015/pod01/init/launcher is ok
file /srv/17311646700765639015/pod01/data/.system/innodb/ is ok
file /srv/17311646700765639015/pod01/init/start is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/optimizer.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/sharedpool.cnf is ok
file /srv/17311646700765639015/pod01/init/MYSQL_ROOT_PASSWORD is ok
file /srv/17311646700765639015/pod01/etc/mysql/smallredolog.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logsqlerror.cnf is ok
file /srv/17311646700765639015/pod01/data/.system/logs/ is ok
file /srv/17311646700765639015/pod01/etc/mysql/logs.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/logslow.cnf is ok
file /srv/17311646700765639015/pod01/etc/mysql/network.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/smallredolog.cnf -> ../smallredolog.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/logslow.cnf -> ../logslow.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/threadpool.cnf -> ../threadpool.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/noquerycache.cnf -> ../noquerycache.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/semisync.cnf -> ../semisync.cnf is ok
symlink /srv/17311646700765639015/pod01/etc/mysql/rc.d/innodb.cnf -> ../innodb.cnf is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.db.cnf
0 error
total duration: 0:00:00.209349
13:01:17,584 container#0001 INFO    docker start 83c9084e17f7480d19a674f489d0f06de582c125eae653481663682c891a577c
13:01:17,779 container#0001 INFO    output:
83c9084e17f7480d19a674f489d0f06de582c125eae653481663682c891a577c
13:01:17,793 container#0001 INFO    wait for up status
13:01:17,822 container#0001 INFO    wait for container operational
13:01:17,869 ip#01          INFO    skip allocate: an ip is already defined
13:01:17,943 ip#01          INFO    checking 192.168.100.71 availability
13:01:21,005 ip#01          INFO    bridge mode
13:01:21,034 ip#01          INFO    create symlink /var/run/netns/27021 -> /proc/27021/ns/net
13:01:21,113 ip#01          INFO    /sbin/ip link add name veth1pl27021 mtu 1500 type veth peer name veth1pg27021 mtu 1500
13:01:21,119 ip#01          INFO    /sbin/ip link set veth1pl27021 master br0
13:01:21,124 ip#01          INFO    /sbin/ip link set veth1pl27021 up
13:01:21,128 ip#01          INFO    /sbin/ip link set veth1pg27021 netns 27021
13:01:21,139 ip#01          INFO    /sbin/ip netns exec 27021 ip link set veth1pg27021 name eth1
13:01:21,194 ip#01          INFO    /sbin/ip netns exec 27021 ip addr add 192.168.100.71/24 dev eth1
13:01:21,282 ip#01          INFO    /sbin/ip netns exec 27021 ip link set eth1 up
13:01:21,322 ip#01          INFO    /sbin/ip netns exec 27021 ip route replace default via 192.168.100.254
13:01:21,368 ip#01          INFO    remove /var/run/netns/27021
13:01:21,515 container#2001 INFO    docker run -d --name=17311646700765639015.container.2001 --net=container:17311646700765639015.container.0001 -e MYSQL_ROOT_PASSWORD=mariadb -e MYSQL_INITDB_SKIP_TZINFO=yes -v /etc/localtime:/etc/localtime:ro -v /srv/17311646700765639015/pod01/data:/var/lib/mysql:rw -v /srv/17311646700765639015/pod01/etc/mysql:/etc/mysql:rw -v /srv/17311646700765639015/pod01/init:/docker-entrypoint-initdb.d:rw --rm --cgroup-parent /17311646700765639015/container.docker/container.2001 mariadb:10.2
13:01:21,743 container#2001 INFO    output:
4628760dbe856a097709f5dbb6e713490cc2d6502e275bc9e3db294eb50b3719
13:01:21,756 container#2001 INFO    wait for up status
13:01:21,781 container#2001 INFO    wait for container operational
13:01:21,995                INFO    send /etc/opensvc/17311646700765639015.conf to collector
13:01:21,995                INFO    update /var/lib/opensvc/17311646700765639015/last_pushed_config timestamp
a stack has been saved to the rpc log

2017/08/08 15:01:26 [ux_dck_zpool_loop] INFO  - Waiting for database start 192.168.100.71
2017/08/08 15:01:26 [ux_dck_zpool_loop] INFO  - Database started
2017/08/08 15:01:32 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.50 3307
2017/08/08 15:01:32 [ux_dck_zpool_loop] ERROR - MaxScale server name undiscovered
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - INF00001 CLOSING Server 192.168.100.71 is down
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster db servers down
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:01:32 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/08 15:01:34 [ux_dck_zpool_loop] INFO  - 13:01:29,035 disk#00        INFO    already provisionned
13:01:29,106 disk#00        INFO    loop /srv/10940044185188150515_docker.dsk is already up
13:01:29,176 disk#0000      INFO    already provisionned
13:01:29,183 disk#0000      INFO    zp10940044185188150515_00 is already up
13:01:29,190 disk#01        INFO    already provisionned
13:01:29,266 disk#01        INFO    loop /srv/10940044185188150515_pod01.dsk is already up
13:01:29,339 disk#1001      INFO    already provisionned
13:01:29,346 disk#1001      INFO    zp10940044185188150515_pod01 is already up
13:01:29,360 fs#00          INFO    /sbin/zfs set refquota=2048M zp10940044185188150515_00/docker
13:01:29,369 fs#00          INFO    provisioned
13:01:29,380 fs#00          INFO    zfs zp10940044185188150515_00/docker@/srv/10940044185188150515/docker is already mounted
13:01:29,395 fs#01          INFO    /sbin/zfs set refquota=1024M zp10940044185188150515_pod01/pod01
13:01:29,404 fs#01          INFO    provisioned
13:01:29,413 fs#01          INFO    zfs zp10940044185188150515_pod01/pod01@/srv/10940044185188150515/pod01 is already mounted
13:01:29,413 fs#01          INFO    /usr/bin/svcmgr -s 10940044185188150515 push service status;/usr/bin/svcmgr -s 10940044185188150515 compliance fix --attach --moduleset mariadb.svc.mrm.proxy
13:01:31,400 fs#01          INFO    output:
moduleset mariadb.svc.mrm.proxy is already attached to this service
========================= mariadb.svc.mrm.proxy.cnf ==========================
ACTION:   check
file //srv/10940044185188150515/pod01/conf/maxscale.cnf is ok
file /srv/10940044185188150515/pod01/init/launcher is ok
file //srv/10940044185188150515/pod01/log/ is ok
file //srv/10940044185188150515/pod01/data/ is ok
file //srv/10940044185188150515/pod01/conf/config-haproxy.toml is ok
file //srv/10940044185188150515/pod01/init/ is ok
file //srv/10940044185188150515/pod01/conf/ is ok
file //srv/10940044185188150515/pod01/conf/keepalived.conf is ok
file //srv/10940044185188150515/pod01/conf/config.toml is ok
STATUS:   ok
check passed, skip fix
=================================== digest ===================================
0 n/a
1 passed
 mariadb.svc.mrm.proxy.cnf
0 error
total duration: 0:00:00.106747
13:01:31,478 container#0001 INFO    container docker container 10940044185188150515.container.0001@busybox:latest already started on node-1-2
13:01:31,522 ip#01          INFO    skip allocate: an ip is already defined
13:01:31,582 ip#01          INFO    192.168.100.50 is already up on br0
13:01:31,714 container#2001 INFO    container docker container 10940044185188150515.container.2001@asosso/maxscale:latest already started on node-1-2
13:01:31,928                INFO    send /etc/opensvc/10940044185188150515.conf to collector
13:01:31,929                INFO    update /var/lib/opensvc/10940044185188150515/last_pushed_config timestamp

2017/08/08 15:01:37 [ux_dck_zpool_loop] INFO  - Cleaning up replication on existing servers
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/08 15:01:37 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/08 15:01:47 [ux_dck_zpool_loop] INFO  - Environment bootstrapped with 192.168.100.70 as master
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster db servers down
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/08 15:01:47 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/08 15:01:47 [ux_dck_zpool_loop] INFO  - Waiting Bootstrap and discovery
2017/08/08 15:01:49 [ux_dck_zpool_loop] INFO  - Waiting Bootstrap and discovery
2017/08/08 15:01:49 [ux_dck_zpool_loop] INFO  - Cluster is Bootstraped and discovery
2017/08/08 15:01:49 [ux_dck_zpool_loop] INFO  - Init maxscale 192.168.100.50 3307
2017/08/08 15:01:49 [ux_dck_zpool_loop] INFO  - Waiting for cluster start
2017/08/08 15:01:51 [ux_dck_zpool_loop] STATE - ERR00017 Unable to fetch MaxScale monitoring information
2017/08/08 15:01:51 [ux_dck_zpool_loop] INFO  - Waiting for cluster start
2017/08/08 15:01:51 [ux_dck_zpool_loop] INFO  - Cluster was started
2017/08/08 15:01:51 [ux_dck_zpool_loop] INFO  - Starting Test testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS
2017/08/08 15:01:51 [ux_dck_zpool_loop] BENCH - PreparedExecConcurrent2 10 iterations
 31.458794ms 	    318 queries/sec	    1409 allocs/query	    124620 B/query

Finished... Total running time: 46.531169ms

2017/08/08 15:01:53 [ux_dck_zpool_loop] STATE - ERR00017 CLOSING Unable to fetch MaxScale monitoring information
2017/08/08 15:01:59 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Slave to Suspect
2017/08/08 15:01:59 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:01:59 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:01:59 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:01:59 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.71 is down
2017/08/08 15:01:59 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/08 15:02:06 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/08 15:02:06 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/08 15:02:19 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 1/3
2017/08/08 15:02:19 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from StandAlone to Suspect
2017/08/08 15:02:23 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:02:23 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:02:24 [ux_dck_zpool_loop] INFO  - Master Failure detected! Retry 2/3
2017/08/08 15:02:28 [ux_dck_zpool_loop] INFO  - Starting Database service 17311646700765639015
2017/08/08 15:02:28 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/08 15:02:28 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/08 15:02:29 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.70 as failed
2017/08/08 15:02:29 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Suspect to Failed
2017/08/08 15:02:30 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:32 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:34 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:36 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:37 [ux_dck_zpool_loop] STATE - ERR00010 CLOSING Could not find a slave in topology
2017/08/08 15:02:37 [ux_dck_zpool_loop] ERROR - Slave wants to rejoin non discovered master
2017/08/08 15:02:38 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:40 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:41 [ux_dck_zpool_loop] STATE - ERR00021 CLOSING All cluster db servers down
2017/08/08 15:02:41 [ux_dck_zpool_loop] STATE - WARN0050 No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:02:41 [ux_dck_zpool_loop] STATE - WARN0056 No compression of binlog on slave 192.168.100.71
2017/08/08 15:02:41 [ux_dck_zpool_loop] STATE - WARN0058 No GTID strict mode on slave 192.168.100.71
2017/08/08 15:02:42 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:44 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:46 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:48 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:50 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:52 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:54 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:56 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:02:58 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:00 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:02 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:04 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:06 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:08 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:10 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:12 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:14 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:16 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:18 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:20 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:22 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:24 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:26 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:28 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:28 [ux_dck_zpool_loop] ERROR - Rejoin timeout
2017/08/08 15:03:33 [ux_dck_zpool_loop] INFO  - Starting Database service 4832677178583133704
2017/08/08 15:03:35 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:37 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:39 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:41 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:43 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:45 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:47 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:49 [ux_dck_zpool_loop] INFO  - Trying to rejoin restarted server 192.168.100.70
2017/08/08 15:03:49 [ux_dck_zpool_loop] STATE - INF00001 CLOSING Server 192.168.100.70 is down
2017/08/08 15:03:49 [ux_dck_zpool_loop] STATE - ERR00012 CLOSING Could not find a master in topology
2017/08/08 15:03:49 [ux_dck_zpool_loop] STATE - WARN0068 No compression of binlog on slave 192.168.100.70
2017/08/08 15:03:49 [ux_dck_zpool_loop] STATE - WARN0070 No GTID strict mode on master 192.168.100.70
2017/08/08 15:03:49 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:51 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:53 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:55 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:57 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:03:59 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:01 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:03 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:05 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:07 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:09 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:11 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:13 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:15 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:17 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:19 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:21 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:23 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:25 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:27 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:29 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:31 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:33 [ux_dck_zpool_loop] INFO  - Waiting Rejoin
2017/08/08 15:04:33 [ux_dck_zpool_loop] ERROR - Rejoin timeout
2017/08/08 15:04:48 [ux_dck_zpool_loop] INFO  - Checksum master table replication_manager_schema.bench =  4134263539 192.168.100.70
2017/08/08 15:04:48 [ux_dck_zpool_loop] INFO  - Number of rows master table replication_manager_schema.bench = 1 192.168.100.70
2017/08/08 15:04:48 [ux_dck_zpool_loop] INFO  - Max Value in bench table replication_manager_schema.bench = 11 192.168.100.70
2017/08/08 15:04:48 [ux_dck_zpool_loop] INFO  - Checksum slave table replication_manager_schema.bench = 4134263539 on 192.168.100.71 
2017/08/08 15:04:48 [ux_dck_zpool_loop] INFO  - Number of rows slave table replication_manager_schema.bench =  1 192.168.100.71
2017/08/08 15:04:48 [ux_dck_zpool_loop] INFO  - Max Value in bench table replication_manager_schema.bench = 11 192.168.100.71
2017/08/08 15:04:49 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:04:49 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:04:49 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:04:49 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:04:49 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:04:49 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:04:49 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:04:51 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:04:51 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:04:51 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:04:51 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:04:51 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:04:51 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:04:51 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:04:51 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:04:54 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:04:54 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:04:54 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:04:54 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:04:54 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:04:54 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:04:54 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:04:54 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:04:54 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:04:56 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:04:56 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:04:56 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:04:56 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:04:56 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:04:56 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:04:56 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:04:56 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:04:56 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:04:58 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:04:58 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:04:58 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:04:58 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:04:58 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:04:58 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:04:58 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:04:58 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:04:58 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:00 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:00 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:00 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:00 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:00 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:00 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:00 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:00 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:00 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:02 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:02 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:02 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:02 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:02 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:02 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:02 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:02 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:02 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:04 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:04 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:04 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:04 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:04 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:04 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:04 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:04 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:04 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:06 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:06 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:06 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:06 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:06 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:06 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:06 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:06 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:06 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:08 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:08 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:08 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:08 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:08 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:08 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:08 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:08 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:08 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:10 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:14 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:14 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:15 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:16 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:16 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:17 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:18 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:18 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:19 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:20 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:20 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:21 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:22 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:22 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:23 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:24 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:24 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:25 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:26 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:26 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:26 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:27 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:27 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:27 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:28 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:28 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:29 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:30 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:30 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:32 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:33 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:33 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:34 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:35 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:35 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:36 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:37 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:37 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:38 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:39 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:39 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:40 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:41 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:41 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:42 [ux_dck_zpool_loop] DEBUG - In Failover skip topology detection
2017/08/08 15:05:43 [ux_dck_zpool_loop] INFO  - In Failover, skip checking failed master
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:43 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:44 [ux_dck_zpool_loop] INFO  - hostlist: 192.168.100.70,192.168.100.71 [192.168.100.70 192.168.100.71]
2017/08/08 15:05:44 [ux_dck_zpool_loop] INFO  - Loading 1 proxies
2017/08/08 15:05:44 [ux_dck_zpool_loop] INFO  - Loading Maxscale...
2017/08/08 15:05:44 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:46 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - WARN0068 CLOSING No compression of binlog on slave 192.168.100.70
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - WARN0070 CLOSING No GTID strict mode on master 192.168.100.70
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - WARN0050 CLOSING No Heartbeat <= 1s on slave 192.168.100.71
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - WARN0056 CLOSING No compression of binlog on slave 192.168.100.71
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - WARN0058 CLOSING No GTID strict mode on slave 192.168.100.71
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - INF00001 Server 192.168.100.70 is down
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - WARN0045 Provision task is in queue
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - ERR00018 Could not connect to MaxScale: Error reading from buffer
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - ERR00010 Could not find a slave in topology
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - ERR00012 Could not find a master in topology
2017/08/08 15:05:47 [ux_dck_zpool_loop] STATE - ERR00021 All cluster db servers down
2017/08/08 15:05:48 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:48 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from  to Suspect
2017/08/08 15:05:48 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from  to Suspect
2017/08/08 15:05:50 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:52 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:53 [ux_dck_zpool_loop] STATE - WARN0045 CLOSING Provision task is in queue
2017/08/08 15:05:54 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:56 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:58 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:05:59 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.71 as failed
2017/08/08 15:05:59 [ux_dck_zpool_loop] ALERT - Server 192.168.100.71 state changed from Suspect to Failed
2017/08/08 15:05:59 [ux_dck_zpool_loop] INFO  - Declaring server 192.168.100.70 as failed
2017/08/08 15:05:59 [ux_dck_zpool_loop] ALERT - Server 192.168.100.70 state changed from Suspect to Failed
2017/08/08 15:06:00 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:02 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:04 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:06 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:08 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:10 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:12 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:14 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:16 [ux_dck_zpool_loop] INFO  - Waiting for cluster shutdown
2017/08/08 15:06:16 [ux_dck_zpool_loop] INFO  - Cluster is shutdown
2017/08/08 15:06:16 [ux_dck_zpool_loop] TEST  - Result FailoverSemisyncAutoRejoinSafeMSMXXXRXSMS                -> {testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS PASS ././config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/replication-manager.conf {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/1.1.0-preview3-101-g480629e/testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=true)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=1) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.50 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=false) unknown %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1,node-1-2 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254 docker node-1-2 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/replication-manager.conf} {/var/lib/replication-manager /usr/local/share/mrm root:mariadb 192.168.100.70,192.168.100.71     root:mariadb %!s(bool=false) %!s(bool=false)    192.168.100.70  %!s(int64=5000) %!s(int64=10) %!s(int=10) %!s(bool=false) %!s(bool=false) %!s(int64=0) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) %!s(bool=true) ./config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/1.1.0-preview3-101-g480629e/testFailoverSemisyncAutoRejoinSafeMSMXXXRXSMS.log %!s(int64=2) %!s(int=1) tcp %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(int=3) %!s(int=5) %!s(bool=false) %!s(bool=false) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(uint64=1000000000) %!s(bool=true) %!s(bool=true) %!s(bool=false) %!s(bool=false)  %!s(bool=false) %!s(bool=false) %!s(bool=false) localhost 10001 %!s(bool=true) ../../dashboard %!s(bool=false) %!s(bool=true) %!s(int=3600) %!s(bool=true) mrm@localhost  localhost:25 %!s(int=10) %!s(int=999) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int64=300) %!s(int64=0) %!s(bool=false) %!s(bool=false) %!s(int=3) %!s(int=14) %!s(bool=false) %!s(int=80) %!s(bool=false) %!s(bool=false) 127.0.0.1:3307 admin %!s(bool=true) 192.168.100.50 3307 admin mariadb %!s(int=4007) %!s(int=4008) %!s(int=4006) %!s(int=3307) %!s(bool=false) %!s(int=3309) %!s(bool=false) maxadmin %!s(bool=false) %!s(bool=false) %!s(int=3306) %!s(int=3307) %!s(int=1988) 0.0.0.0 0.0.0.0 /usr/sbin/haproxy /etc/replication-manager/.replication-manager.key %!s(int=0) %!s(bool=true) %!s(bool=false) master-slave %!s(bool=false) %!s(bool=false) 127.0.0.1 %!s(int=2003) %!s(int=10002) %!s(int=10003) %!s(int=7002) %!s(int=2004) %!s(int=7007) /usr/local/bin/sysbench %!s(int=60) %!s(int=4) /usr/local/mysql/bin %!s(bool=false)  88.191.151.84:80 %!s(int=0) 127.0.0.1:10002 %!s(bool=false) %!s(bool=true) %!s(bool=false) %!s(bool=true) 192.168.100.101:443 root@localhost.localdomain:opensvc replication-manager@localhost.localdomain:mariadb docker node-1-1,node-1-2 256 300 smallredolog,semisync,innodb,noquerycache,threadpool,logslow 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254 docker node-1-2 1G zfs zpool /srv loopback br0 255.255.255.0 192.168.100.254     mariadb:10.2 asosso/maxscale:latest admin:mariadb 3000 ././config/masterslave/mariadb/without_traffic/10.2/x2/semisync/innodb/maxscale/latest/x1/replication-manager.conf}}
